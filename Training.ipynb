{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f457cb8a-3fca-4584-9a16-b293c7948729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d192331-d1b2-4307-8de9-0fe0fba438a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image=cv2.resize(image, (28,28), interpolation=cv2.INTER_CUBIC)\n",
    "    image=tf.image.rgb_to_grayscale(image)\n",
    "    image = np.reshape(image, (-1, 28, 28, 1))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "197a9369-60ee-451e-8cc5-6667f34a1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(image):\n",
    "    arr=model(image)\n",
    "    return np.argmax(arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf53fe41-be89-4bb5-acad-91ff33c35c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
    "        layers.Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10,activation=tf.keras.activations.softmax),\n",
    "    ],\n",
    "    name=\"Model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2579538-ada9-4003-86ad-f072e3d64a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 14, 14, 256)       2560      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 256)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 512)         1180160   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                250890    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1433610 (5.47 MB)\n",
      "Trainable params: 1433610 (5.47 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f73ed477-1a48-4f16-afc6-627883a35d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# Normalize data\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
    "\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "x_test = np.reshape(x_test, (-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fbe7168-15ac-40eb-a03c-b93789e560b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping as callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6302547d-a6b9-4c18-9755-981038dfd684",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1997459-181d-4704-bf7e-fc6959668786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.1545 - sparse_categorical_accuracy: 0.9523\n",
      "Epoch 1: saving model to training_1\\cp.ckpt\n",
      "1500/1500 [==============================] - 258s 172ms/step - loss: 0.1545 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.0891 - val_sparse_categorical_accuracy: 0.9741\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0949 - sparse_categorical_accuracy: 0.9715\n",
      "Epoch 2: saving model to training_1\\cp.ckpt\n",
      "1500/1500 [==============================] - 250s 167ms/step - loss: 0.0949 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.1120 - val_sparse_categorical_accuracy: 0.9693\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0843 - sparse_categorical_accuracy: 0.9752\n",
      "Epoch 3: saving model to training_1\\cp.ckpt\n",
      "1500/1500 [==============================] - 276s 184ms/step - loss: 0.0843 - sparse_categorical_accuracy: 0.9752 - val_loss: 0.1022 - val_sparse_categorical_accuracy: 0.9729\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0774 - sparse_categorical_accuracy: 0.9770\n",
      "Epoch 4: saving model to training_1\\cp.ckpt\n",
      "1500/1500 [==============================] - 274s 183ms/step - loss: 0.0774 - sparse_categorical_accuracy: 0.9770 - val_loss: 0.0946 - val_sparse_categorical_accuracy: 0.9761\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0701 - sparse_categorical_accuracy: 0.9804\n",
      "Epoch 5: saving model to training_1\\cp.ckpt\n",
      "1500/1500 [==============================] - 278s 185ms/step - loss: 0.0701 - sparse_categorical_accuracy: 0.9804 - val_loss: 0.0915 - val_sparse_categorical_accuracy: 0.9777\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0645 - sparse_categorical_accuracy: 0.9823\n",
      "Epoch 6: saving model to training_1\\cp.ckpt\n",
      "1500/1500 [==============================] - 278s 185ms/step - loss: 0.0645 - sparse_categorical_accuracy: 0.9823 - val_loss: 0.0928 - val_sparse_categorical_accuracy: 0.9791\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0686 - sparse_categorical_accuracy: 0.9820\n",
      "Epoch 7: saving model to training_1\\cp.ckpt\n",
      "1500/1500 [==============================] - 263s 175ms/step - loss: 0.0686 - sparse_categorical_accuracy: 0.9820 - val_loss: 0.1380 - val_sparse_categorical_accuracy: 0.9724\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0538 - sparse_categorical_accuracy: 0.9855\n",
      "Epoch 8: saving model to training_1\\cp.ckpt\n",
      "1500/1500 [==============================] - 280s 187ms/step - loss: 0.0538 - sparse_categorical_accuracy: 0.9855 - val_loss: 0.1162 - val_sparse_categorical_accuracy: 0.9779\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0629 - sparse_categorical_accuracy: 0.9847\n",
      "Epoch 9: saving model to training_1\\cp.ckpt\n",
      "1500/1500 [==============================] - 279s 186ms/step - loss: 0.0629 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.1637 - val_sparse_categorical_accuracy: 0.9739\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0536 - sparse_categorical_accuracy: 0.9875\n",
      "Epoch 10: saving model to training_1\\cp.ckpt\n",
      "1500/1500 [==============================] - 277s 185ms/step - loss: 0.0536 - sparse_categorical_accuracy: 0.9875 - val_loss: 0.2312 - val_sparse_categorical_accuracy: 0.9616\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# Train and evaluate teacher on data.\n",
    "history =model.fit(x_train, y_train,validation_split=0.2, epochs=10,callbacks=[early_stopping,cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fae6528d-bbe5-490e-b274-ac1e21627e0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 10s 31ms/step - loss: 0.2196 - sparse_categorical_accuracy: 0.9619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21956877410411835, 0.961899995803833]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "212059d2-946c-4e41-bef3-1ba69d1288ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./sekpoint/model.keras\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ebab766-991b-462f-97a9-5530b7856d3d",
   "metadata": {},
   "source": [
    "#run from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fab841b-8ebf-48b6-bfd1-4b521414a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"./sekpoint/model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76260822-b1c8-4580-89d5-31f2074bc873",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('mnist_6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c955e7a0-1c4c-4d80-9114-4b645f0ba1a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image\u001b[38;5;241m=\u001b[39m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m, in \u001b[0;36mpreprocess\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(image):\n\u001b[1;32m----> 2\u001b[0m     image\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTER_CUBIC\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     image\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mrgb_to_grayscale(image)\n\u001b[0;32m      4\u001b[0m     image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(image, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "image=preprocess(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9bf90cc-8ca3-40ef-9f36-ff8732f12009",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbec1005-bc7b-43e3-8e64-3575387f88bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresult\u001b[49m(image)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "result(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221f16e3-9c9b-4b82-8525-d303729ab8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d526c63-4620-4f37-af17-389033cc89cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937752ac-4c6d-493a-9869-edcfe693122b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c3b418-02e4-4450-b3e0-eaec3955c491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ab99623-8eac-4b25-b769-16a82ae46d4e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
